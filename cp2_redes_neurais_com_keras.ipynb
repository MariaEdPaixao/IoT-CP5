{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaEdPaixao/IoT-CP5/blob/main/cp2_redes_neurais_com_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CP2 parte 1 - Redes Neurais com Keras\n",
        "\n",
        "## Integrantes - 2TDSPJ\n",
        "\n",
        "*   **RM 558843** - Laura de Oliveira Cintra\n",
        "\n",
        "*   **RM 558832** - Maria Eduarda Alves da Paixão\n",
        "\n",
        "*   **RM 554456** - Vinícius Saes de Souza\n"
      ],
      "metadata": {
        "id": "QL55R1qlI1-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Exercício 1*\n",
        "Dataset: Wine Dataset (UCI)\n",
        "\n",
        "`O dataset Wine é um conjunto de dados clássico usado para classificação. Ele contém 178 amostras de vinho, com 13 características (variáveis) para cada amostra, como níveis de componentes químicos e propriedades físicas dos vinhos.`\n",
        "\n",
        "Essas características são usadas para classificar os vinhos em duas classes (tipos de vinho).\n",
        "1. Treinar uma rede neural em Keras para classificar vinhos em 3 classes.\n",
        "- Configuração mínima: 2 camadas ocultas com 32 neurônios cada, função de ativação ReLU.\n",
        "- Camada de saída com 3 neurônios, função de ativação Softmax.\n",
        "- Função de perda: categorical_crossentropy.\n",
        "- Otimizador: Adam.\n",
        "2. Comparar os resultados com um modelo do scikit-learn (RandomForestClassifier ou\n",
        "LogisticRegression).\n",
        "3. Registrar métricas de acurácia e discutir qual modelo teve melhor desempenho.\n"
      ],
      "metadata": {
        "id": "wYdzXQmGJFol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1° - Importar bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, callbacks, utils\n",
        "\n",
        "# Reprodutibilidade\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "FO9SJBPtJCN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zWpMepzIJrJ",
        "outputId": "b4b573ab-bbf1-4cb1-d97f-9b7a78366f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensão de X: (178, 13)\n",
            "Classes: [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "# 2° - Carregar dataset Wine\n",
        "data = load_wine(as_frame=True) # objeto do tipo Bunch (um dicionário especial do Scikit-Learn).\n",
        "X = data.data # data.data -> As features (colunas com os atributos do vinho, como álcool, acidez, etc.)\n",
        "y = data.target # data.target -> O rótulo (classe do vinho: 0, 1 ou 2)\n",
        "\n",
        "print(\"Dimensão de X:\", X.shape)\n",
        "print(\"Classes:\", np.unique(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "EU0Nyn1PNZ-v",
        "outputId": "a21d39c3-9d7e-47fc-bc69-dbb6e63dcff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "173    2\n",
              "174    2\n",
              "175    2\n",
              "176    2\n",
              "177    2\n",
              "Name: target, Length: 178, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# o data é um objeto especial do scikit-learn, por isso não da pra usar .head() nele, portanto para ver o dataset completo:\n",
        "print(data.keys())\n",
        "\n",
        "data.frame # Um DataFrame completo, que já junta data e target em uma tabela só"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "7OMojMf_K4Hr",
        "outputId": "50d8738b-8474-4a30-943e-e4acdd4f7d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  target  \n",
              "0                            3.92   1065.0       0  \n",
              "1                            3.40   1050.0       0  \n",
              "2                            3.17   1185.0       0  \n",
              "3                            3.45   1480.0       0  \n",
              "4                            2.93    735.0       0  \n",
              "..                            ...      ...     ...  \n",
              "173                          1.74    740.0       2  \n",
              "174                          1.56    750.0       2  \n",
              "175                          1.56    835.0       2  \n",
              "176                          1.62    840.0       2  \n",
              "177                          1.60    560.0       2  \n",
              "\n",
              "[178 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6fdd21d-8b2c-490e-9752-b64428c1913a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6fdd21d-8b2c-490e-9752-b64428c1913a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6fdd21d-8b2c-490e-9752-b64428c1913a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6fdd21d-8b2c-490e-9752-b64428c1913a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de1c92f7-1614-4488-8ef3-d343c8debde8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de1c92f7-1614-4488-8ef3-d343c8debde8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de1c92f7-1614-4488-8ef3-d343c8debde8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 178,\n  \"fields\": [\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8118265380058577,\n        \"min\": 11.03,\n        \"max\": 14.83,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          11.62,\n          13.64,\n          13.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"malic_acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1171460976144627,\n        \"min\": 0.74,\n        \"max\": 5.8,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          1.21,\n          2.83,\n          1.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2743440090608148,\n        \"min\": 1.36,\n        \"max\": 3.23,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          2.31,\n          2.43,\n          2.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcalinity_of_ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3395637671735052,\n        \"min\": 10.6,\n        \"max\": 30.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          25.5,\n          28.5,\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"magnesium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.282483515295668,\n        \"min\": 70.0,\n        \"max\": 162.0,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          126.0,\n          85.0,\n          162.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6258510488339891,\n        \"min\": 0.98,\n        \"max\": 3.88,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1.68,\n          2.11,\n          1.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flavanoids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9988586850169465,\n        \"min\": 0.34,\n        \"max\": 5.08,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          3.18,\n          2.5,\n          3.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nonflavanoid_phenols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12445334029667939,\n        \"min\": 0.13,\n        \"max\": 0.66,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.58,\n          0.41,\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"proanthocyanins\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5723588626747611,\n        \"min\": 0.41,\n        \"max\": 3.58,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.75,\n          1.77,\n          1.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"color_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.318285871822413,\n        \"min\": 1.28,\n        \"max\": 13.0,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          2.95,\n          3.3,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22857156582982338,\n        \"min\": 0.48,\n        \"max\": 1.71,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          1.22,\n          1.04,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"od280/od315_of_diluted_wines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7099904287650505,\n        \"min\": 1.27,\n        \"max\": 4.0,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          4.0,\n          1.82,\n          1.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"proline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314.9074742768489,\n        \"min\": 278.0,\n        \"max\": 1680.0,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          1375.0,\n          1270.0,\n          735.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão treino/teste (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Normalizar features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "R3Z_xSnhK3Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3° - Criar e treinar rede neural Keras\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# One-hot encoding para labels\n",
        "y_train_oh = utils.to_categorical(y_train, num_classes)\n",
        "y_test_oh = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Construir modelo\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(num_features,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Treinar com early stopping\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_oh,\n",
        "    validation_split=0.15,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    callbacks=[es],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ0OILllJr4w",
        "outputId": "91ca2ec0-ecea-454a-adac-0f5f65306690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5605 - loss: 1.0223 - val_accuracy: 0.3182 - val_loss: 1.0920\n",
            "Epoch 2/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6401 - loss: 0.8920 - val_accuracy: 0.4545 - val_loss: 0.9318\n",
            "Epoch 3/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7138 - loss: 0.7945 - val_accuracy: 0.6818 - val_loss: 0.7909\n",
            "Epoch 4/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8460 - loss: 0.7107 - val_accuracy: 0.9091 - val_loss: 0.6731\n",
            "Epoch 5/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9110 - loss: 0.6365 - val_accuracy: 1.0000 - val_loss: 0.5724\n",
            "Epoch 6/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9201 - loss: 0.5683 - val_accuracy: 1.0000 - val_loss: 0.4841\n",
            "Epoch 7/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9384 - loss: 0.5037 - val_accuracy: 1.0000 - val_loss: 0.4080\n",
            "Epoch 8/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.4427 - val_accuracy: 1.0000 - val_loss: 0.3417\n",
            "Epoch 9/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.3857 - val_accuracy: 1.0000 - val_loss: 0.2849\n",
            "Epoch 10/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9745 - loss: 0.3336 - val_accuracy: 1.0000 - val_loss: 0.2364\n",
            "Epoch 11/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9745 - loss: 0.2871 - val_accuracy: 1.0000 - val_loss: 0.1963\n",
            "Epoch 12/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9687 - loss: 0.2466 - val_accuracy: 1.0000 - val_loss: 0.1634\n",
            "Epoch 13/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9781 - loss: 0.2127 - val_accuracy: 1.0000 - val_loss: 0.1365\n",
            "Epoch 14/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9781 - loss: 0.1842 - val_accuracy: 1.0000 - val_loss: 0.1148\n",
            "Epoch 15/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9852 - loss: 0.1599 - val_accuracy: 1.0000 - val_loss: 0.0970\n",
            "Epoch 16/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.1390 - val_accuracy: 1.0000 - val_loss: 0.0824\n",
            "Epoch 17/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.1212 - val_accuracy: 1.0000 - val_loss: 0.0703\n",
            "Epoch 18/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.1063 - val_accuracy: 1.0000 - val_loss: 0.0604\n",
            "Epoch 19/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0935 - val_accuracy: 1.0000 - val_loss: 0.0522\n",
            "Epoch 20/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.0456\n",
            "Epoch 21/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0734 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
            "Epoch 22/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0656 - val_accuracy: 1.0000 - val_loss: 0.0353\n",
            "Epoch 23/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9981 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
            "Epoch 24/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0531 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 25/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0480 - val_accuracy: 1.0000 - val_loss: 0.0250\n",
            "Epoch 26/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0435 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 27/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0395 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
            "Epoch 28/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0360 - val_accuracy: 1.0000 - val_loss: 0.0182\n",
            "Epoch 29/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
            "Epoch 30/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0150\n",
            "Epoch 31/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 32/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
            "Epoch 33/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
            "Epoch 34/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
            "Epoch 35/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
            "Epoch 36/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
            "Epoch 37/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
            "Epoch 38/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
            "Epoch 39/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
            "Epoch 40/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
            "Epoch 41/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 42/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 43/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
            "Epoch 44/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 45/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
            "Epoch 46/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
            "Epoch 47/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 48/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 49/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
            "Epoch 50/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 51/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 52/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 53/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 54/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 55/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 56/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 57/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 58/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 59/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 60/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 61/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
            "Epoch 62/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
            "Epoch 63/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 64/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
            "Epoch 65/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
            "Epoch 66/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 67/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 68/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 69/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 70/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 71/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 72/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 73/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 74/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 75/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 76/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 77/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 78/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 79/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 80/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 81/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 82/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 9.8552e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 9.5598e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 9.2738e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 9.0009e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.7365e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.4852e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 8.2441e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 8.0163e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 7.7970e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 7.5865e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 7.3764e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 7.1785e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 6.9909e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 6.8110e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 6.6347e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 6.4640e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 6.3011e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 6.1432e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 5.9939e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 5.8509e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 5.7111e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 5.5722e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 5.4407e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 5.3139e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 5.1924e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 5.0733e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.9571e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.8447e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.7353e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.6307e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.5286e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.4293e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.3337e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 4.2414e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 4.1516e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 4.0626e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.9783e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.8972e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.8182e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.7395e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.8686e-04 - val_accuracy: 1.0000 - val_loss: 3.6639e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.6860e-04 - val_accuracy: 1.0000 - val_loss: 3.5915e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.5100e-04 - val_accuracy: 1.0000 - val_loss: 3.5205e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.3359e-04 - val_accuracy: 1.0000 - val_loss: 3.4508e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.1601e-04 - val_accuracy: 1.0000 - val_loss: 3.3837e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.9963e-04 - val_accuracy: 1.0000 - val_loss: 3.3187e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.8358e-04 - val_accuracy: 1.0000 - val_loss: 3.2555e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.6765e-04 - val_accuracy: 1.0000 - val_loss: 3.1932e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.5219e-04 - val_accuracy: 1.0000 - val_loss: 3.1331e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 8.3744e-04 - val_accuracy: 1.0000 - val_loss: 3.0746e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.2272e-04 - val_accuracy: 1.0000 - val_loss: 3.0179e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.0819e-04 - val_accuracy: 1.0000 - val_loss: 2.9623e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.9427e-04 - val_accuracy: 1.0000 - val_loss: 2.9084e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 7.8101e-04 - val_accuracy: 1.0000 - val_loss: 2.8564e-04\n",
            "Epoch 136/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.6785e-04 - val_accuracy: 1.0000 - val_loss: 2.8049e-04\n",
            "Epoch 137/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.5496e-04 - val_accuracy: 1.0000 - val_loss: 2.7552e-04\n",
            "Epoch 138/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.4236e-04 - val_accuracy: 1.0000 - val_loss: 2.7058e-04\n",
            "Epoch 139/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.2993e-04 - val_accuracy: 1.0000 - val_loss: 2.6587e-04\n",
            "Epoch 140/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.1796e-04 - val_accuracy: 1.0000 - val_loss: 2.6124e-04\n",
            "Epoch 141/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.0631e-04 - val_accuracy: 1.0000 - val_loss: 2.5674e-04\n",
            "Epoch 142/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.9483e-04 - val_accuracy: 1.0000 - val_loss: 2.5226e-04\n",
            "Epoch 143/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.8334e-04 - val_accuracy: 1.0000 - val_loss: 2.4794e-04\n",
            "Epoch 144/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.7250e-04 - val_accuracy: 1.0000 - val_loss: 2.4375e-04\n",
            "Epoch 145/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.6185e-04 - val_accuracy: 1.0000 - val_loss: 2.3964e-04\n",
            "Epoch 146/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.5150e-04 - val_accuracy: 1.0000 - val_loss: 2.3567e-04\n",
            "Epoch 147/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.4129e-04 - val_accuracy: 1.0000 - val_loss: 2.3173e-04\n",
            "Epoch 148/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.3125e-04 - val_accuracy: 1.0000 - val_loss: 2.2793e-04\n",
            "Epoch 149/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.2146e-04 - val_accuracy: 1.0000 - val_loss: 2.2424e-04\n",
            "Epoch 150/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.1209e-04 - val_accuracy: 1.0000 - val_loss: 2.2057e-04\n",
            "Epoch 151/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.0274e-04 - val_accuracy: 1.0000 - val_loss: 2.1690e-04\n",
            "Epoch 152/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.9341e-04 - val_accuracy: 1.0000 - val_loss: 2.1342e-04\n",
            "Epoch 153/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.8453e-04 - val_accuracy: 1.0000 - val_loss: 2.1002e-04\n",
            "Epoch 154/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.7579e-04 - val_accuracy: 1.0000 - val_loss: 2.0667e-04\n",
            "Epoch 155/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.6725e-04 - val_accuracy: 1.0000 - val_loss: 2.0339e-04\n",
            "Epoch 156/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.5880e-04 - val_accuracy: 1.0000 - val_loss: 2.0017e-04\n",
            "Epoch 157/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 5.5044e-04 - val_accuracy: 1.0000 - val_loss: 1.9702e-04\n",
            "Epoch 158/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.4240e-04 - val_accuracy: 1.0000 - val_loss: 1.9403e-04\n",
            "Epoch 159/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.3462e-04 - val_accuracy: 1.0000 - val_loss: 1.9105e-04\n",
            "Epoch 160/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.2695e-04 - val_accuracy: 1.0000 - val_loss: 1.8808e-04\n",
            "Epoch 161/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.1945e-04 - val_accuracy: 1.0000 - val_loss: 1.8523e-04\n",
            "Epoch 162/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.1194e-04 - val_accuracy: 1.0000 - val_loss: 1.8236e-04\n",
            "Epoch 163/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.0456e-04 - val_accuracy: 1.0000 - val_loss: 1.7962e-04\n",
            "Epoch 164/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.9747e-04 - val_accuracy: 1.0000 - val_loss: 1.7696e-04\n",
            "Epoch 165/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.9058e-04 - val_accuracy: 1.0000 - val_loss: 1.7434e-04\n",
            "Epoch 166/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.8375e-04 - val_accuracy: 1.0000 - val_loss: 1.7174e-04\n",
            "Epoch 167/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.7713e-04 - val_accuracy: 1.0000 - val_loss: 1.6924e-04\n",
            "Epoch 168/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.7056e-04 - val_accuracy: 1.0000 - val_loss: 1.6676e-04\n",
            "Epoch 169/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.6391e-04 - val_accuracy: 1.0000 - val_loss: 1.6430e-04\n",
            "Epoch 170/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.5752e-04 - val_accuracy: 1.0000 - val_loss: 1.6196e-04\n",
            "Epoch 171/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.5129e-04 - val_accuracy: 1.0000 - val_loss: 1.5965e-04\n",
            "Epoch 172/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.4526e-04 - val_accuracy: 1.0000 - val_loss: 1.5737e-04\n",
            "Epoch 173/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.3927e-04 - val_accuracy: 1.0000 - val_loss: 1.5514e-04\n",
            "Epoch 174/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.3344e-04 - val_accuracy: 1.0000 - val_loss: 1.5294e-04\n",
            "Epoch 175/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.2765e-04 - val_accuracy: 1.0000 - val_loss: 1.5080e-04\n",
            "Epoch 176/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.2192e-04 - val_accuracy: 1.0000 - val_loss: 1.4869e-04\n",
            "Epoch 177/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.1645e-04 - val_accuracy: 1.0000 - val_loss: 1.4663e-04\n",
            "Epoch 178/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.1099e-04 - val_accuracy: 1.0000 - val_loss: 1.4460e-04\n",
            "Epoch 179/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.0565e-04 - val_accuracy: 1.0000 - val_loss: 1.4262e-04\n",
            "Epoch 180/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.0041e-04 - val_accuracy: 1.0000 - val_loss: 1.4068e-04\n",
            "Epoch 181/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.9534e-04 - val_accuracy: 1.0000 - val_loss: 1.3875e-04\n",
            "Epoch 182/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.9020e-04 - val_accuracy: 1.0000 - val_loss: 1.3689e-04\n",
            "Epoch 183/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8521e-04 - val_accuracy: 1.0000 - val_loss: 1.3505e-04\n",
            "Epoch 184/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.8037e-04 - val_accuracy: 1.0000 - val_loss: 1.3324e-04\n",
            "Epoch 185/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.7557e-04 - val_accuracy: 1.0000 - val_loss: 1.3146e-04\n",
            "Epoch 186/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 3.7082e-04 - val_accuracy: 1.0000 - val_loss: 1.2972e-04\n",
            "Epoch 187/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.6621e-04 - val_accuracy: 1.0000 - val_loss: 1.2800e-04\n",
            "Epoch 188/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.6156e-04 - val_accuracy: 1.0000 - val_loss: 1.2632e-04\n",
            "Epoch 189/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.5705e-04 - val_accuracy: 1.0000 - val_loss: 1.2469e-04\n",
            "Epoch 190/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.5270e-04 - val_accuracy: 1.0000 - val_loss: 1.2306e-04\n",
            "Epoch 191/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.4844e-04 - val_accuracy: 1.0000 - val_loss: 1.2148e-04\n",
            "Epoch 192/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.4413e-04 - val_accuracy: 1.0000 - val_loss: 1.1991e-04\n",
            "Epoch 193/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.3996e-04 - val_accuracy: 1.0000 - val_loss: 1.1836e-04\n",
            "Epoch 194/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.3585e-04 - val_accuracy: 1.0000 - val_loss: 1.1684e-04\n",
            "Epoch 195/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.3180e-04 - val_accuracy: 1.0000 - val_loss: 1.1537e-04\n",
            "Epoch 196/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.2784e-04 - val_accuracy: 1.0000 - val_loss: 1.1392e-04\n",
            "Epoch 197/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.2390e-04 - val_accuracy: 1.0000 - val_loss: 1.1251e-04\n",
            "Epoch 198/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2007e-04 - val_accuracy: 1.0000 - val_loss: 1.1111e-04\n",
            "Epoch 199/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.1626e-04 - val_accuracy: 1.0000 - val_loss: 1.0972e-04\n",
            "Epoch 200/200\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.1253e-04 - val_accuracy: 1.0000 - val_loss: 1.0835e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4° - Avaliar modelo neural\n",
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_oh, verbose=0)\n",
        "print(f\"Acurácia no conjunto de teste (Keras): {test_acc:.4f}\")\n",
        "\n",
        "# Previsões e métricas\n",
        "y_pred_nn = np.argmax(model.predict(X_test_scaled), axis=1)\n",
        "print(\"\\nRelatório de classificação (Keras):\")\n",
        "print(classification_report(y_test, y_pred_nn, digits=4))\n",
        "print(\"Matriz de confusão (Keras):\\n\", confusion_matrix(y_test, y_pred_nn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdj1kWlOJ1dl",
        "outputId": "f67e86a7-d6ea-4764-ad00-f8887c43440a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste (Keras): 1.0000\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "Relatório de classificação (Keras):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        12\n",
            "           1     1.0000    1.0000    1.0000        14\n",
            "           2     1.0000    1.0000    1.0000        10\n",
            "\n",
            "    accuracy                         1.0000        36\n",
            "   macro avg     1.0000    1.0000    1.0000        36\n",
            "weighted avg     1.0000    1.0000    1.0000        36\n",
            "\n",
            "Matriz de confusão (Keras):\n",
            " [[12  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5° - Gráficos de treino/validação\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='treino')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('Função de perda (Loss)')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='treino')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Acurácia')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "KBwCVabaKNyx",
        "outputId": "3a76ab11-34e5-4a24-dc2c-0731548dd7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6° - Comparar com modelos clássicos\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"\\nAcurácia RandomForest: {acc_rf:.4f}\")\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs', random_state=42)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Acurácia Logistic Regression: {acc_lr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTpAVLesKU1o",
        "outputId": "1a0208eb-3bb7-465b-ebf4-8fc34fe85760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acurácia RandomForest: 1.0000\n",
            "Acurácia Logistic Regression: 0.9722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7° - Comparar resultados\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    ['Rede Neural (Keras)', test_acc],\n",
        "    ['Random Forest', acc_rf],\n",
        "    ['Logistic Regression', acc_lr]\n",
        "], columns=['Modelo', 'Acurácia de Teste'])\n",
        "\n",
        "print(\"\\nResumo dos Resultados:\")\n",
        "display(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "egeU_3vWKfga",
        "outputId": "f097a37c-d5d8-4ad2-ebb0-2d83ea4ddf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resumo dos Resultados:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Modelo  Acurácia de Teste\n",
              "0  Rede Neural (Keras)           1.000000\n",
              "1        Random Forest           1.000000\n",
              "2  Logistic Regression           0.972222"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b7c412b-b93c-4d36-8f8f-48479bb4aa69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Acurácia de Teste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rede Neural (Keras)</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.972222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7c412b-b93c-4d36-8f8f-48479bb4aa69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b7c412b-b93c-4d36-8f8f-48479bb4aa69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b7c412b-b93c-4d36-8f8f-48479bb4aa69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53aeb95b-97c5-4b9d-8842-8c8630439b9a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53aeb95b-97c5-4b9d-8842-8c8630439b9a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53aeb95b-97c5-4b9d-8842-8c8630439b9a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2232e7bc-81f0-4e60-8cd8-fa4fe6b1ea64\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2232e7bc-81f0-4e60-8cd8-fa4fe6b1ea64 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Rede Neural (Keras)\",\n          \"Random Forest\",\n          \"Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acur\\u00e1cia de Teste\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016037507477489613,\n        \"min\": 0.9722222222222222,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9722222222222222,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* **Registrar métricas de acurácia e discutir qual modelo teve melhor desempenho.**\n",
        "\n",
        "Os resultados mostraram que a rede neural e o modelo Random Forest tiveram 100% de acurácia, ou seja, acertaram todas as classificações. Já a Regressão Logística teve 97,22%, que também é um resultado muito bom. No geral, os dois primeiros modelos tiveram o melhor desempenho, mas o Random Forest é mais simples de usar e treinar do que a rede neural."
      ],
      "metadata": {
        "id": "H42j77X8LuOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Exercício 2*\n",
        "Dataset: California Housing Dataset\n",
        "\n",
        "`O dataset California Housing é um conjunto de dados clássico de regressão. Ele contém informações sobre diferentes distritos habitacionais, com o objetivo de prever o valor médio das casas em cada região.`\n",
        "\n",
        "1. Treinar uma rede neural em **Keras** para prever o valor médio das casas.  \n",
        "   - Configuração mínima: 3 camadas ocultas com 64, 32 e 16 neurônios, função de ativação **ReLU**.  \n",
        "   - Camada de saída com 1 neurônio, função de ativação **Linear**.  \n",
        "   - Função de perda: **mse**.  \n",
        "   - Otimizador: **Adam**.  \n",
        "2. Comparar os resultados com um modelo do **scikit-learn** (*LinearRegression* ou *RandomForestRegressor*).  \n",
        "3. Registrar métricas de erro (**RMSE** ou **MAE**) e discutir qual modelo teve melhor desempenho."
      ],
      "metadata": {
        "id": "owzyhiTvEHfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1° - Importar bibliotecas\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "9mfDdgf9Ls_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1° - Carregar e inspecionar o dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data_cal = fetch_california_housing(as_frame=True)\n",
        "X_reg = data_cal.data\n",
        "y_reg = data_cal.target\n",
        "\n",
        "print('Shape X_reg:', X_reg.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxn684gsHYYl",
        "outputId": "49b6073f-ebf0-47a4-f8d8-3f72f9e2472e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_reg: (20640, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2° - Separar treino e teste (80/20)\n",
        "Xreg_train, Xreg_test, yreg_train, yreg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "print('Train shape:', Xreg_train.shape, 'Test shape:', Xreg_test.shape)\n",
        "\n",
        "# Normalizar features\n",
        "scaler = StandardScaler()\n",
        "Xreg_train_scaled = scaler.fit_transform(Xreg_train)\n",
        "Xreg_test_scaled = scaler.transform(Xreg_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJjjN_a3IEGG",
        "outputId": "cb5ea698-b47f-4240-bb6a-bba2bdf53887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (16512, 8) Test shape: (4128, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3° - Construir modelo Keras para regressão\n",
        "model_reg = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(Xreg_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model_reg.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nGzixN-J9Cn",
        "outputId": "d2d75a28-e9de-460d-efdb-db850715bc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar a estrutura do modelo\n",
        "model_reg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "jWrgGpqZVHLQ",
        "outputId": "709a3b51-7397-4f98-c3b7-85644d379fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,605\u001b[0m (37.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,605</span> (37.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,201\u001b[0m (12.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> (12.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,404\u001b[0m (25.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,404</span> (25.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4° - Treinar modelo\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model_reg.fit(\n",
        "    Xreg_train_scaled, yreg_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "q0KdvOAbKKDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3a7450-341a-4619-ee32-7e1759498956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.3730 - mae: 0.8309 - val_loss: 0.4308 - val_mae: 0.4678\n",
            "Epoch 2/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3882 - mae: 0.4448 - val_loss: 0.3875 - val_mae: 0.4426\n",
            "Epoch 3/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3528 - mae: 0.4201 - val_loss: 0.3696 - val_mae: 0.4310\n",
            "Epoch 4/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3355 - mae: 0.4072 - val_loss: 0.3536 - val_mae: 0.4212\n",
            "Epoch 5/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3226 - mae: 0.3980 - val_loss: 0.3449 - val_mae: 0.4111\n",
            "Epoch 6/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3135 - mae: 0.3906 - val_loss: 0.3320 - val_mae: 0.4047\n",
            "Epoch 7/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3044 - mae: 0.3834 - val_loss: 0.3311 - val_mae: 0.3986\n",
            "Epoch 8/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2993 - mae: 0.3771 - val_loss: 0.3220 - val_mae: 0.3941\n",
            "Epoch 9/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2916 - mae: 0.3714 - val_loss: 0.3218 - val_mae: 0.3903\n",
            "Epoch 10/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2866 - mae: 0.3666 - val_loss: 0.3177 - val_mae: 0.3883\n",
            "Epoch 11/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2822 - mae: 0.3630 - val_loss: 0.3130 - val_mae: 0.3826\n",
            "Epoch 12/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2787 - mae: 0.3598 - val_loss: 0.3086 - val_mae: 0.3817\n",
            "Epoch 13/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2765 - mae: 0.3582 - val_loss: 0.3097 - val_mae: 0.3819\n",
            "Epoch 14/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2725 - mae: 0.3552 - val_loss: 0.3070 - val_mae: 0.3800\n",
            "Epoch 15/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2703 - mae: 0.3538 - val_loss: 0.3064 - val_mae: 0.3795\n",
            "Epoch 16/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2682 - mae: 0.3521 - val_loss: 0.3016 - val_mae: 0.3788\n",
            "Epoch 17/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2659 - mae: 0.3505 - val_loss: 0.3014 - val_mae: 0.3775\n",
            "Epoch 18/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2639 - mae: 0.3488 - val_loss: 0.3014 - val_mae: 0.3794\n",
            "Epoch 19/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2634 - mae: 0.3487 - val_loss: 0.3043 - val_mae: 0.3783\n",
            "Epoch 20/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2617 - mae: 0.3475 - val_loss: 0.3026 - val_mae: 0.3788\n",
            "Epoch 21/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2602 - mae: 0.3465 - val_loss: 0.3007 - val_mae: 0.3757\n",
            "Epoch 22/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2579 - mae: 0.3449 - val_loss: 0.3007 - val_mae: 0.3780\n",
            "Epoch 23/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2570 - mae: 0.3443 - val_loss: 0.3005 - val_mae: 0.3772\n",
            "Epoch 24/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2566 - mae: 0.3443 - val_loss: 0.2978 - val_mae: 0.3740\n",
            "Epoch 25/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2536 - mae: 0.3420 - val_loss: 0.2947 - val_mae: 0.3722\n",
            "Epoch 26/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2523 - mae: 0.3410 - val_loss: 0.2944 - val_mae: 0.3731\n",
            "Epoch 27/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2517 - mae: 0.3400 - val_loss: 0.2953 - val_mae: 0.3746\n",
            "Epoch 28/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2514 - mae: 0.3398 - val_loss: 0.2952 - val_mae: 0.3730\n",
            "Epoch 29/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2499 - mae: 0.3389 - val_loss: 0.2948 - val_mae: 0.3733\n",
            "Epoch 30/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2484 - mae: 0.3378 - val_loss: 0.2933 - val_mae: 0.3701\n",
            "Epoch 31/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2478 - mae: 0.3372 - val_loss: 0.2936 - val_mae: 0.3709\n",
            "Epoch 32/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2466 - mae: 0.3364 - val_loss: 0.2908 - val_mae: 0.3695\n",
            "Epoch 33/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2456 - mae: 0.3354 - val_loss: 0.2928 - val_mae: 0.3700\n",
            "Epoch 34/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2456 - mae: 0.3355 - val_loss: 0.2918 - val_mae: 0.3692\n",
            "Epoch 35/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2448 - mae: 0.3346 - val_loss: 0.2917 - val_mae: 0.3689\n",
            "Epoch 36/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2432 - mae: 0.3337 - val_loss: 0.2919 - val_mae: 0.3695\n",
            "Epoch 37/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2437 - mae: 0.3341 - val_loss: 0.2922 - val_mae: 0.3693\n",
            "Epoch 38/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2418 - mae: 0.3328 - val_loss: 0.2916 - val_mae: 0.3689\n",
            "Epoch 39/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2418 - mae: 0.3329 - val_loss: 0.2913 - val_mae: 0.3689\n",
            "Epoch 40/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2410 - mae: 0.3321 - val_loss: 0.2939 - val_mae: 0.3704\n",
            "Epoch 41/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2406 - mae: 0.3321 - val_loss: 0.2900 - val_mae: 0.3688\n",
            "Epoch 42/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2430 - mae: 0.3335 - val_loss: 0.2901 - val_mae: 0.3695\n",
            "Epoch 43/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2394 - mae: 0.3310 - val_loss: 0.2919 - val_mae: 0.3701\n",
            "Epoch 44/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2387 - mae: 0.3305 - val_loss: 0.2883 - val_mae: 0.3675\n",
            "Epoch 45/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2378 - mae: 0.3296 - val_loss: 0.2898 - val_mae: 0.3685\n",
            "Epoch 46/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2365 - mae: 0.3287 - val_loss: 0.2881 - val_mae: 0.3663\n",
            "Epoch 47/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2359 - mae: 0.3281 - val_loss: 0.2884 - val_mae: 0.3673\n",
            "Epoch 48/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2351 - mae: 0.3282 - val_loss: 0.2881 - val_mae: 0.3652\n",
            "Epoch 49/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2357 - mae: 0.3284 - val_loss: 0.2890 - val_mae: 0.3667\n",
            "Epoch 50/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2346 - mae: 0.3273 - val_loss: 0.2879 - val_mae: 0.3655\n",
            "Epoch 51/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2331 - mae: 0.3262 - val_loss: 0.2870 - val_mae: 0.3650\n",
            "Epoch 52/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2325 - mae: 0.3262 - val_loss: 0.2875 - val_mae: 0.3654\n",
            "Epoch 53/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2317 - mae: 0.3256 - val_loss: 0.2866 - val_mae: 0.3651\n",
            "Epoch 54/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2310 - mae: 0.3250 - val_loss: 0.2874 - val_mae: 0.3653\n",
            "Epoch 55/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2305 - mae: 0.3245 - val_loss: 0.2883 - val_mae: 0.3657\n",
            "Epoch 56/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2306 - mae: 0.3245 - val_loss: 0.2864 - val_mae: 0.3640\n",
            "Epoch 57/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2296 - mae: 0.3242 - val_loss: 0.2857 - val_mae: 0.3639\n",
            "Epoch 58/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2295 - mae: 0.3239 - val_loss: 0.2869 - val_mae: 0.3647\n",
            "Epoch 59/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2280 - mae: 0.3227 - val_loss: 0.2872 - val_mae: 0.3646\n",
            "Epoch 60/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2279 - mae: 0.3229 - val_loss: 0.2882 - val_mae: 0.3650\n",
            "Epoch 61/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2269 - mae: 0.3220 - val_loss: 0.2871 - val_mae: 0.3643\n",
            "Epoch 62/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2264 - mae: 0.3218 - val_loss: 0.2877 - val_mae: 0.3639\n",
            "Epoch 63/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2256 - mae: 0.3207 - val_loss: 0.2871 - val_mae: 0.3640\n",
            "Epoch 64/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2245 - mae: 0.3204 - val_loss: 0.2875 - val_mae: 0.3638\n",
            "Epoch 65/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2251 - mae: 0.3212 - val_loss: 0.2857 - val_mae: 0.3633\n",
            "Epoch 66/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2249 - mae: 0.3212 - val_loss: 0.2860 - val_mae: 0.3633\n",
            "Epoch 67/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2239 - mae: 0.3201 - val_loss: 0.2839 - val_mae: 0.3626\n",
            "Epoch 68/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2222 - mae: 0.3188 - val_loss: 0.2859 - val_mae: 0.3630\n",
            "Epoch 69/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2225 - mae: 0.3194 - val_loss: 0.2868 - val_mae: 0.3633\n",
            "Epoch 70/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2226 - mae: 0.3194 - val_loss: 0.2873 - val_mae: 0.3642\n",
            "Epoch 71/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2224 - mae: 0.3191 - val_loss: 0.2860 - val_mae: 0.3636\n",
            "Epoch 72/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2215 - mae: 0.3188 - val_loss: 0.2843 - val_mae: 0.3624\n",
            "Epoch 73/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2217 - mae: 0.3186 - val_loss: 0.2850 - val_mae: 0.3641\n",
            "Epoch 74/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2202 - mae: 0.3177 - val_loss: 0.2839 - val_mae: 0.3637\n",
            "Epoch 75/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2194 - mae: 0.3172 - val_loss: 0.2864 - val_mae: 0.3642\n",
            "Epoch 76/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2193 - mae: 0.3167 - val_loss: 0.2897 - val_mae: 0.3639\n",
            "Epoch 77/100\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2199 - mae: 0.3171 - val_loss: 0.2878 - val_mae: 0.3668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5° - Avaliar\n",
        "y_pred = model_reg.predict(Xreg_test_scaled).ravel()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(yreg_test, y_pred))\n",
        "mae = mean_absolute_error(yreg_test, y_pred)\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulKYNE0-NB7A",
        "outputId": "3457599c-2d9c-438d-daf2-0232dd27dacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step\n",
            "RMSE: 0.5356\n",
            "MAE: 0.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6° - Comparar com outros modelos\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(Xreg_train_scaled, yreg_train)\n",
        "y_pred_lr = lr.predict(Xreg_train_scaled)\n",
        "rmse_lr = np.sqrt(mean_squared_error(yreg_train, y_pred_lr))\n",
        "mae_lr = mean_absolute_error(yreg_train, y_pred_lr)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(random_state=42, n_estimators=200)\n",
        "rf.fit(Xreg_train, yreg_train)\n",
        "y_pred_rf = rf.predict(Xreg_train)\n",
        "rmse_rf = np.sqrt(mean_squared_error(yreg_train, y_pred_rf))\n",
        "mae_rf = mean_absolute_error(yreg_train, y_pred_rf)"
      ],
      "metadata": {
        "id": "nWxsQD4LRrUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7° Comparativo\n",
        "summary2 = pd.DataFrame({\n",
        "    \"Modelo\": [\"Rede Neural (Keras)\", \"Linear Regression\", \"Random Forest\"],\n",
        "    \"RMSE\": [rmse, rmse_lr, rmse_rf],\n",
        "    \"MAE\": [mae, mae_lr, mae_rf]\n",
        "})\n",
        "\n",
        "summary2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GzSg6GcjRxt_",
        "outputId": "e8a77aa7-c21d-4c02-b6a5-c770a89796fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Modelo      RMSE       MAE\n",
              "0  Rede Neural (Keras)  0.535648  0.362524\n",
              "1    Linear Regression  0.719676  0.528628\n",
              "2        Random Forest  0.185695  0.121036"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89d509ff-ac33-490e-a686-10c41566f040\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rede Neural (Keras)</td>\n",
              "      <td>0.535648</td>\n",
              "      <td>0.362524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.719676</td>\n",
              "      <td>0.528628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.185695</td>\n",
              "      <td>0.121036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89d509ff-ac33-490e-a686-10c41566f040')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89d509ff-ac33-490e-a686-10c41566f040 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89d509ff-ac33-490e-a686-10c41566f040');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e029b025-5e06-419c-a785-a4c9a60b4456\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e029b025-5e06-419c-a785-a4c9a60b4456')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e029b025-5e06-419c-a785-a4c9a60b4456 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_71bf69e2-d2c0-43d9-ac20-b7c22e66a4a3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_71bf69e2-d2c0-43d9-ac20-b7c22e66a4a3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary2",
              "summary": "{\n  \"name\": \"summary2\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Rede Neural (Keras)\",\n          \"Linear Regression\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27125280459727535,\n        \"min\": 0.18569514748260385,\n        \"max\": 0.7196757085831575,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5356482045095414,\n          0.7196757085831575,\n          0.18569514748260385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2049547451470605,\n        \"min\": 0.12103592971778161,\n        \"max\": 0.5286283596581934,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.362523668487675,\n          0.5286283596581934,\n          0.12103592971778161\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Registrar métricas de erro (RMSE ou MAE) e discutir qual modelo teve melhor desempenho.**\n",
        "\n",
        "Observando as métricas de erro apresentadas na tabela de resumo, o modelo **Random Forest** obteve os menores valores (RMSE: 0.1857, MAE: 0.1210), indicando o melhor desempenho para esta tarefa de regressão.\n",
        "\n",
        "A **Rede Neural em Keras** também demonstrou um desempenho robusto e significativamente melhor do que a Regressão Linear, alcançando resultados intermediários (RMSE: 0.5356, MAE: 0.3625). Este resultado indica que a arquitetura neural é eficaz na captura das relações dos dados. Em contraste, a Regressão Linear teve os maiores erros (RMSE: 0.7197, MAE: 0.5286), performando menos eficazmente no dataset.\n",
        "\n",
        "No geral, o **Random Forest** foi o modelo com a melhor performance, mas a **Rede Neural (Keras)** se destacou como um modelo de aprendizado de máquina mais avançado com um bom nível de acurácia, superando o modelo linear clássico."
      ],
      "metadata": {
        "id": "hk6jJM5JZS4o"
      }
    }
  ]
}